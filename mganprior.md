# Image Processing Using Multi-Code GAN Prior

## Summary
Previous methods typically invert a target image back to the latent
space either by back-propagation or by learning an additional encoder. However, the reconstructions from both of
the methods are far from ideal.

In this work, we propose
a novel approach, called mGANprior, to incorporate the
well-trained GANs as effective prior to a variety of image
processing tasks.

In particular, we employ multiple latent
codes to generate multiple feature maps at some intermediate layer of the generator, then compose them with adaptive
channel importance to recover the input image.

The resulting high-fidelity image
reconstruction enables the trained GAN models as prior to
many real-world applications, such as image colorization,
super-resolution, image inpainting, and semantic manipulation. We further analyze the properties of the layer-wise
representation learned by GAN models and shed light on
what knowledge each layer is capable of representing.

## My summary

This paper introduces a new method: mGANprior which perform GAN inversion to multiple latent codes as well latent features.
The architecture is as follows:

![](https://github.com/luulinh90s/paper-review-generative-models/blob/master/mGANprior.JPG)

There are two subnetworks, which ensures that we can achive both latent code and latent features from the generator.

The procedure of this GAN is: Firsly, we do inversion to get latent codes. Secondly, when we want to edit the original image, 
we combine these latent codes with adaptive channel scores (read more in papers) to generate the targeted images for specific tasks (inpainting/colorization ...)

## Experiments
### Compare with other inversion methods
Authors compared with (a) optimizing a single latent code z, (b)
learning an encoder to reverse the generator, and (c)
combing (a) and (b) by using the output of the encoder as
the initialization for further optimization.

For quantitative evaluation, they compute the PSNR score measuring the
similarity between the original input and the reconstruction
result from pixel level and LPIPS metric
which is known to align with human perception.

### Analysis on Inverted Code 

**Number of codes**. In this figure, they showed that as long as the number of codes < 20, when we increase the number of codes, we get better quality of reconstruction.
![](https://github.com/luulinh90s/paper-review-generative-models/blob/master/mGANprior2.JPG)

**On which layer should we perform composition**.
Also in the above image, if we compose the latent codes
on various layers of PGGAN (i.e., from 1st to 8th) and
compare the inversion quality. In general,
a higher composition layer could lead to a better inversion
effect. However, as revealed in past papers, higher layers contain the
information of local pixel patterns such as edges and colors
rather than the high-level semantics. Composing features
at higher layers is hard to reuse of the semantic knowledge
learned by GANs.

**Role of each latent code**. They computeed the IoU between images generated by two different adaptive channel importances to determine each code's role.
This is shown here:
![](https://github.com/luulinh90s/paper-review-generative-models/blob/master/mGANprior3.JPG)

## Open problems

- There are hyperparameters in this papers: 1) number of codes, 2) layer to perform composition.
- In analyzing Role of each latent code, only 20 codes are possible for each image (20 semantics for an image), but I think it will somewhat restrict the sematics in synthesized photos.
