# What Sorts of Distributions Can GANs Model?

- We note that ‘a high number of classes is what makes ImageNet synthesis difficult for GANs’. 
These observations are supported by the empirical fact that the state-of-the-art image synthesis model 
on CelebA generates images that seem substantially more convincing than the state-of-the-art image synthesis model on Imagenet.
- Are there distributions that a GAN can never learn to model? Are there distributions that are learnable for a GAN in principle, 
but are not efficiently learnable, for some reasonable model of resource-consumption? 
Are the answers to these questions actually any different for GANs than they are for other generative models?

# How Can we Scale GANs Beyond Image Synthesis?
# What can we Say About the Global Convergence of GAN Training?
# How Should we Evaluate GANs and When Should we Use Them?
# What is the Relationship Between GANs and Adversarial Examples?
