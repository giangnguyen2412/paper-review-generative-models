# Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks

## Summary
Generative models fall into two categories: 
- parametric: 
- non-parametric: do matching from a database of existing images, often matching patches of images, and have been used in texture synthesis, super-resolution and in-painting.

This paper is called Unsupervised Representation Learning because the discriminator learns immediate features without any direct labels. 

The core to this paper is:

 - replace deterministic spatial pooling functions by strided convolutions. This helps network learn its own spatial downsampling. They apply on both G and D.
 - instead of using fully connected layers on top of conv layers, they remove them and use a Tanh activation function at the end. Of course the output is needed being shaped.
 - they apply batch norm after every conv layers and the first embedding layer except the last conv layer.
 
 Hyperparameters for training:
 - batch = 128
 - activation func: Leaky ReLU with 0.2 slope
 - lr for both 0.0002
 - momemtum: 0.5
 - latent dim z space: 100
